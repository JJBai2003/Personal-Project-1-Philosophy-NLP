{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13eceb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"plato.txt\",'r') as plato, open(\"stoicism.txt\", 'r') as stoicism, open(\"scepticism.txt\",'r') as scepticism:\n",
    "    plato_text = plato.read()\n",
    "    stoicism_text = stoicism.read()\n",
    "    scepticism_text = scepticism.read()\n",
    "with open(\"aristotle.txt\",'r') as aristotle, open(\"epicureanism.txt\", 'r') as epicurean:\n",
    "    aristotle_text = aristotle.read()\n",
    "    epicureanism_text = epicurean.read()\n",
    "texts_comp = plato_text + stoicism_text + scepticism_text + aristotle_text + epicureanism_text\n",
    "school_dict = {\"plato\": plato_text, \"stoicism\": stoicism_text, \"scepticism\": scepticism_text, \n",
    "              \"aristotle\": aristotle_text, \"epicureanism\": epicureanism_text}\n",
    "score_classes = {\"plato\": 1, \"stoicism\": 2, \"scepticism\": 3, \n",
    "              \"aristotle\": 4, \"epicureanism\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "004925e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "33e3a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "list_pairs = []\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "tokenize_plato = tokenize.sent_tokenize(plato_text)\n",
    "downsample_plato = resample(tokenize_plato,\n",
    "             replace=True,\n",
    "             n_samples=len(aristotle_text),\n",
    "             random_state=42)\n",
    "\n",
    "for i in downsample_plato:\n",
    "    X.append(i)\n",
    "    y.append(score_classes[\"plato\"])\n",
    "for i in tokenize.sent_tokenize(stoicism_text):\n",
    "    X.append(i)\n",
    "    y.append(score_classes[\"stoicism\"])\n",
    "for i in tokenize.sent_tokenize(scepticism_text):\n",
    "    X.append(i)\n",
    "    y.append(score_classes[\"scepticism\"])\n",
    "for i in tokenize.sent_tokenize(aristotle_text):\n",
    "    X.append(i)\n",
    "    y.append(score_classes[\"aristotle\"])\n",
    "for i in tokenize.sent_tokenize(epicureanism_text):\n",
    "    X.append(i)\n",
    "    y.append(score_classes[\"epicureanism\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "394f353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=.3)\n",
    "tfidvectorizer = TfidfVectorizer(decode_error='ignore', stop_words=[])\n",
    "tf_idf_data_train = tfidvectorizer.fit_transform(X_train)\n",
    "tf_idf_data_test = tfidvectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ae6b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#developing a model\n",
    "decision_tree = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,\n",
    "                               max_depth=10, min_samples_leaf=30)\n",
    "decision_tree.fit(tf_idf_data_train, y_train)\n",
    "dec_predict = decision_tree.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a783fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      1.00      0.99    145562\n",
      "           2       0.64      0.09      0.16       953\n",
      "           3       0.84      0.06      0.12       914\n",
      "           4       1.00      0.11      0.19      1078\n",
      "           5       0.96      0.10      0.17       525\n",
      "\n",
      "    accuracy                           0.98    149032\n",
      "   macro avg       0.89      0.27      0.33    149032\n",
      "weighted avg       0.98      0.98      0.97    149032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, dec_predict))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c221ee2",
   "metadata": {},
   "source": [
    "Notes on Bag of Words:\n",
    "- Extract features from text: vocabb of known words and a measure of presence of known words\n",
    "- Simplest scoring method: mark the presence of the word using booleans (0:= absent, 1:= present) and each vector of encoded sentence has length <total number of known vocabs> <-  disgard orders, cases, punctuation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a10e924d",
   "metadata": {},
   "source": [
    "Notes on Decision Tree: \n",
    "https://adityagoel123.medium.com/multi-class-classification-using-decision-tree-model-68e75114303"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
